{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask 1\n",
    "\n",
    "## Aim of the task: \n",
    "Analysis of data fetched by perceval on a per-quarter basis.  \n",
    "This includes (but not limited to) :\n",
    "- The number of new committers per quarter\n",
    "- The number of new issue and pull request submitters per quarter\n",
    "- The total number of issues, commits and pull requests per quarter\n",
    "\n",
    "This task has been done in Python without using any libraries like pandas or numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Getting the data\n",
    "The data used for this microtask is the same as that used for the previous microtasks. Please check microtask 0 to see the cell output generated by running the commented script present two cells below this one. \n",
    "The cell below helps understand the data to be fetched, like the **owner**, the **repository names**, the **repository urls** and most importantly the **github authentication token**.  \n",
    "\n",
    "**Make sure to fill in your token for the `auth_token` variable in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/\"  # the github url domain: used for generating repo_urls\n",
    "owner = \"atom\"\n",
    "repos_used = [\"language-java\", \"teletype\"]\n",
    "repo_urls = [github_url + owner + \"/\" + repo_used for repo_used in repos_used]\n",
    "auth_token = \"\" # Please enter your github token here\n",
    "file_name = owner + \".json\" # file to which perceval stores data (a ../ is automatically added)\n",
    "csv_name = owner + \".csv\" # file to which csv data is written (a ../ is automatically added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harnessing the power of jupyter notebooks \n",
    "The script in the cell below is a generalized way to create and populate a json file using perceval.  \n",
    "\n",
    "The steps involved are simple: \n",
    "For each repository specified in the `repos_used` variable, fetch its git data, its pull_requests data and finally its issues data from the github api in that order and append them to the json file. \n",
    "\n",
    "**Note**: it has been commented out to prevent an accidental overwrite of the json file, present in the parent directory of our present directory. To work on more recent data, or to perform an analysis on a completely different set of repositories (make sure to change the variables in the cell above), please uncomment the snippet below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo, repo_url in zip(repos_used, repo_urls):\n",
    "#     print(repo, repo_url)\n",
    "\n",
    "#     !perceval git --json-line $repo_url >> ../$file_name\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category pull_request $owner $repo >> ../$file_name\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category issue $owner $repo >> ../$file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a few constants\n",
    "**start_year and end_year**:\n",
    "    these denote the range of quarters we'll be considering. For example, the current usage implies that 12 quarters will be considered for this metric. Thus, the end_year will be considered. The date ranges for the quarters have been fixed and stored in dictionaries as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here both start year and end year are included\n",
    "start_year = 2017\n",
    "end_year = 2019\n",
    "\n",
    "# This dicts represent the range of dates which fall into each quarter\n",
    "quar1_dates = {\"start_date\": \"01-01\", \"end_date\": \"03-31\"}\n",
    "quar2_dates = {\"start_date\": \"04-01\", \"end_date\": \"06-30\"}\n",
    "quar3_dates = {\"start_date\": \"07-01\", \"end_date\": \"09-30\"}\n",
    "quar4_dates = {\"start_date\": \"10-01\", \"end_date\": \"12-31\"}\n",
    "\n",
    "# These sets allow one to track the number of new contributers for each item (commit, pull request, issue)\n",
    "old_committers = set()\n",
    "old_issue_subs = set()\n",
    "old_pr_subs = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Quarter class\n",
    "I was looking for an easy way to represent the collected data. I went with a class representation of a quarter so that when the time comes to analyze data per quarter, all that's left to be done is to use the instance variables of that quarter object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quarter:\n",
    "    \n",
    "    def __init__(self, number, year):\n",
    "        # the quarter number and year (these make a quarter unique (like a candidate key))\n",
    "        self.number = number    \n",
    "        self.year = year   \n",
    "   \n",
    "        # these store the number of commits, issues and pull_requests created during a particular quarter\n",
    "        self.num_commits = 0  \n",
    "        self.num_issues = 0\n",
    "        self.num_pullrequests = 0\n",
    "        \n",
    "        # these store the number of new contributers in that particular quarter\n",
    "        self.new_committers = 0\n",
    "        self.new_issue_subs = 0\n",
    "        self.new_pr_subs = 0\n",
    "        \n",
    "        # these represent the date range over which a particular quarter is valid\n",
    "        self.start_date = \"\"\n",
    "        self.end_date = \"\"\n",
    "        \n",
    "        # populate the self.start_date and self.end_date instance variables\n",
    "        if self.number == 1:\n",
    "            self.start_date = str(self.year) + '-' + quar1_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar1_dates[\"end_date\"]\n",
    "            \n",
    "        if self.number == 2:\n",
    "            self.start_date = str(self.year) + '-' + quar2_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar3_dates[\"end_date\"]            \n",
    "            \n",
    "        if self.number == 3:\n",
    "            self.start_date = str(self.year) + '-' + quar3_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar3_dates[\"end_date\"]\n",
    "            \n",
    "        if self.number == 4:\n",
    "            self.start_date = str(self.year) + '-' + quar4_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar4_dates[\"end_date\"]\n",
    "        \n",
    "            \n",
    "    def is_includes_data(self, date):\n",
    "        \"\"\"\n",
    "        :param data: this is a date in the form of a string which will be converted \n",
    "        into a date time object using the _str_to_dt_data() static method. \n",
    "        \n",
    "        Note: the Quarter instance variables: self.start_date and self.end_date are also strings. \n",
    "        To convert them to a date time object of the same format, _str_to_dt_quarter() is used.\n",
    "        \"\"\"\n",
    "        if self._str_to_dt_quarter(self.start_date) <= self._str_to_dt_data(date) < self._str_to_dt_quarter(self.end_date):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def add_analysis(self, datapoint):\n",
    "        \n",
    "        if datapoint['category'] == \"commit\":\n",
    "            self.num_commits += 1 \n",
    "            \n",
    "            # if the author has already committed before, do nothing\n",
    "            if datapoint['author'] not in old_committers:\n",
    "                self.new_committers += 1\n",
    "                \n",
    "            old_committers.add(datapoint['author'])\n",
    "                \n",
    "        if datapoint['category'] == \"issue\":\n",
    "            self.num_issues += 1 \n",
    "            \n",
    "            if datapoint['author'] not in old_issue_subs:\n",
    "                self.new_issue_subs += 1\n",
    "\n",
    "            old_issue_subs.add(datapoint['author'])\n",
    "            \n",
    "        if datapoint['category'] == \"pull_request\":\n",
    "            self.num_pullrequests += 1 \n",
    "            \n",
    "            if datapoint['author'] not in old_pr_subs:\n",
    "                self.new_pr_subs += 1\n",
    "                \n",
    "            old_pr_subs.add(datapoint['author'])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _str_to_dt_data(date):\n",
    "        \"\"\"\n",
    "        :param date: converts date (str) to a datetime object \n",
    "        Note: the string format for the date in the json file is either: \n",
    "         - %a %b %d %H:%M:%S %Y %z --> for commits\n",
    "         - %Y-%m-%dT%H:%M:%SZ      --> for issues and pull requests\n",
    "        \"\"\"        \n",
    "        try:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%a %b %d %H:%M:%S %Y %z\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        except ValueError as ve:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        finally:\n",
    "            datetimeobj = datetime.datetime.strptime(datetimestr, \"%Y-%m-%d\")\n",
    "            return datetimeobj\n",
    "        \n",
    "    @staticmethod\n",
    "    def _str_to_dt_quarter(date):\n",
    "        \n",
    "        datetimeobj =  datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        return datetimeobj\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.number) + \" \" + str(self.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "This class creates a dictionary with three keys:\n",
    "    - \"commit\"\n",
    "    - \"issue\"\n",
    "    - \"pull_request\"\n",
    "The value of each key is a list, whose elements are indivisual commits, pull requests or issues (based on the key). Each element is of type `dict`\n",
    "\n",
    "Note: in the \\_\\_init\\_\\_ method, you might notice that there is an extra condition for when the category of the data is \"issue\". As mentioned in previous microtasks, the Github API assumes that all pull requests are issues as well, and hence, redundant pull request data is present in the \"issue\" category. \n",
    "The extra condition counters that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanJson():   \n",
    "    \n",
    "    def __init__(self, path_to_file):\n",
    "        \n",
    "        self.clean_data = {\n",
    "            'commit': [],\n",
    "            'issue': [],\n",
    "            'pull_request': []\n",
    "        }\n",
    "        \n",
    "        with open(path_to_file, 'r') as raw_data:\n",
    "            for line in raw_data:\n",
    "                line = json.loads(line)\n",
    "\n",
    "                clean_line = dict()\n",
    "                if line['category'] == \"commit\":\n",
    "                    clean_line = self._clean_commit(line)\n",
    "\n",
    "                elif line['category'] == \"issue\":\n",
    "                    if \"pull_request\" not in line['data']:\n",
    "                        clean_line = self._clean_issue(line)\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "                elif line['category'] == \"pull_request\":\n",
    "                    clean_line = self._clean_pr(line)\n",
    "\n",
    "                self.clean_data[line['category']].append(clean_line)\n",
    "\n",
    "                    \n",
    "    @staticmethod                \n",
    "    def _clean_commit(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        summary = {\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['commit'],\n",
    "            'category': \"commit\",\n",
    "            'commit': line_data['Commit'],\n",
    "            'author': line_data['Author'],\n",
    "            'created_date': line_data['CommitDate'],\n",
    "            'files_no': len(line_data['files'])\n",
    "        }\n",
    "        \n",
    "        actions = 0\n",
    "        \n",
    "        for file in line_data['files']:\n",
    "            if 'action' in file:\n",
    "                actions += 1\n",
    "                summary['files_action'] = actions\n",
    "                summary['merge'] = 'Merge' in line_data\n",
    "        return summary\n",
    "    \n",
    "    @staticmethod\n",
    "    def _clean_issue(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"issue\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "        \n",
    "        return cleaned_line\n",
    "    \n",
    "    @staticmethod\n",
    "    def _clean_pr(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"pull_request\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "        \n",
    "        return cleaned_line\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the required number of quarters\n",
    "The list comprehension below is a general way to create the required quarter objects, depending on the start_year and end_year global variables declared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = [x for x in range(start_year, end_year + 1)]\n",
    "quar_list = [Quarter(num, year)  for year in year_list for num in range(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = CleanJson('../'+ file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the quarter objects\n",
    "The snippet below loops through each key in the clean_data.clean_data dictionary. Remember, the structure of clean_data.clean_data is:\n",
    "```python\n",
    "    {\n",
    "        'commit': [commit1_dict, commit2_dict, ....], \n",
    "        'issue': [issue1_dict, issue2_dict, ....], \n",
    "        'pull_request': [pr1_dict, pr2_dict, ....], \n",
    "    }\n",
    "```\n",
    "For each key, it loop through each quarter object, present in the quar_list list and then decides if each element in the value for that key falls in that quarter. \n",
    "If that is the case, it updates the quarter object's instance variables using the quarter.add_analysis(data_point) method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in (\"commit\", \"issue\", \"pull_request\"):\n",
    "    data = clean_data.clean_data[category]\n",
    "    for quarter in quar_list:\n",
    "        \n",
    "        for data_point in data:\n",
    "            if quarter.is_includes_data(data_point[\"created_date\"]):\n",
    "                quarter.add_analysis(data_point)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "The idea of creating an object for each quarter allows one to easily analyze the data returned by perceval. For each topic, be it number of items, or number of new contributers, simple print the corresponding instance variable for each Quarter object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of commits, pull requests and issues per quadrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter num and year:  1 2017  \n",
      " commits:  14  \n",
      " issues:  2  \n",
      " pull requests:  6\n",
      "--------------------------\n",
      "Quarter num and year:  2 2017  \n",
      " commits:  373  \n",
      " issues:  79  \n",
      " pull requests:  40\n",
      "--------------------------\n",
      "Quarter num and year:  3 2017  \n",
      " commits:  267  \n",
      " issues:  60  \n",
      " pull requests:  32\n",
      "--------------------------\n",
      "Quarter num and year:  4 2017  \n",
      " commits:  521  \n",
      " issues:  146  \n",
      " pull requests:  67\n",
      "--------------------------\n",
      "Quarter num and year:  1 2018  \n",
      " commits:  215  \n",
      " issues:  38  \n",
      " pull requests:  35\n",
      "--------------------------\n",
      "Quarter num and year:  2 2018  \n",
      " commits:  87  \n",
      " issues:  62  \n",
      " pull requests:  27\n",
      "--------------------------\n",
      "Quarter num and year:  3 2018  \n",
      " commits:  10  \n",
      " issues:  25  \n",
      " pull requests:  19\n",
      "--------------------------\n",
      "Quarter num and year:  4 2018  \n",
      " commits:  12  \n",
      " issues:  23  \n",
      " pull requests:  6\n",
      "--------------------------\n",
      "Quarter num and year:  1 2019  \n",
      " commits:  6  \n",
      " issues:  13  \n",
      " pull requests:  7\n",
      "--------------------------\n",
      "Quarter num and year:  2 2019  \n",
      " commits:  0  \n",
      " issues:  0  \n",
      " pull requests:  0\n",
      "--------------------------\n",
      "Quarter num and year:  3 2019  \n",
      " commits:  0  \n",
      " issues:  0  \n",
      " pull requests:  0\n",
      "--------------------------\n",
      "Quarter num and year:  4 2019  \n",
      " commits:  0  \n",
      " issues:  0  \n",
      " pull requests:  0\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for q in quar_list:\n",
    "    print(\"Quarter num and year: \" ,q,    \n",
    "          \" \\n commits: \", q.num_commits,\n",
    "          \" \\n issues: \", q.num_issues, \n",
    "          \" \\n pull requests: \", q.num_pullrequests)\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of new committers, new issue submitters and pull request creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter num and year:  1 2017  \n",
      " new committers:  2  \n",
      " new issue submitters:  2  \n",
      " new pull request creators:  2\n",
      "--------------------------\n",
      "Quarter num and year:  2 2017  \n",
      " new committers:  9  \n",
      " new issue submitters:  23  \n",
      " new pull request creators:  6\n",
      "--------------------------\n",
      "Quarter num and year:  3 2017  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "--------------------------\n",
      "Quarter num and year:  4 2017  \n",
      " new committers:  7  \n",
      " new issue submitters:  74  \n",
      " new pull request creators:  5\n",
      "--------------------------\n",
      "Quarter num and year:  1 2018  \n",
      " new committers:  8  \n",
      " new issue submitters:  28  \n",
      " new pull request creators:  6\n",
      "--------------------------\n",
      "Quarter num and year:  2 2018  \n",
      " new committers:  5  \n",
      " new issue submitters:  47  \n",
      " new pull request creators:  7\n",
      "--------------------------\n",
      "Quarter num and year:  3 2018  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "--------------------------\n",
      "Quarter num and year:  4 2018  \n",
      " new committers:  3  \n",
      " new issue submitters:  12  \n",
      " new pull request creators:  0\n",
      "--------------------------\n",
      "Quarter num and year:  1 2019  \n",
      " new committers:  2  \n",
      " new issue submitters:  6  \n",
      " new pull request creators:  3\n",
      "--------------------------\n",
      "Quarter num and year:  2 2019  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "--------------------------\n",
      "Quarter num and year:  3 2019  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "--------------------------\n",
      "Quarter num and year:  4 2019  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for q in quar_list:\n",
    "    print(\"Quarter num and year: \" ,q,    \n",
    "          \" \\n new committers: \", q.new_committers,\n",
    "          \" \\n new issue submitters: \", q.new_issue_subs, \n",
    "          \" \\n new pull request creators: \", q.new_pr_subs)\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing data as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the cleaned data to a csv\n",
    "The following function takes a file path as a parameter and writes to that file the following: \n",
    "    quarter number and year\n",
    "    number of commits, issues, and pull requests in that quarter\n",
    "    number of new committers, new issue submitters and new pull request creators.\n",
    "    \n",
    "The actual process of writing to the csv is done with the help of the `csv` python package and specifically, `csv.writer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(file_path):\n",
    "    with open(file_path, 'w', ) as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "        \n",
    "        file_headers = [\"Quarter(Num)\", \"Quarter(Year)\", \"Num_Commits\", \"Num_Issues\", \"Num_PRs\", \"Num_new_commits\", \"Num_new_issues\", \"Num_new_prs\"]\n",
    "        csv_writer.writerow(file_headers)\n",
    "        \n",
    "        for quar in quar_list:\n",
    "            row = [str(quar.number),         \\\n",
    "                 str(quar.year),             \\\n",
    "                 str(quar.num_commits) ,     \\\n",
    "                 str(quar.num_issues)  ,     \\\n",
    "                 str(quar.num_pullrequests), \\\n",
    "                 str(quar.new_committers),   \\\n",
    "                 str(quar.new_issue_subs),   \\\n",
    "                 str(quar.new_pr_subs)       \n",
    "                  ]\n",
    "            csv_writer.writerow(x for x in row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(\"../\" + csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying a table based on the csv file\n",
    "The following function creates a table after the reading the csv file created above, allowing one to visualize the data stored in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(file_path):\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            for field in row:\n",
    "                print(\"%-10s\" %field, end=\"\\t\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter(Num)\tQuarter(Year)\tNum_Commits\tNum_Issues\tNum_PRs   \tNum_new_commits\tNum_new_issues\tNum_new_prs\t\n",
      "1         \t2017      \t14        \t2         \t6         \t2         \t2         \t2         \t\n",
      "2         \t2017      \t373       \t79        \t40        \t9         \t23        \t6         \t\n",
      "3         \t2017      \t267       \t60        \t32        \t0         \t0         \t0         \t\n",
      "4         \t2017      \t521       \t146       \t67        \t7         \t74        \t5         \t\n",
      "1         \t2018      \t215       \t38        \t35        \t8         \t28        \t6         \t\n",
      "2         \t2018      \t87        \t62        \t27        \t5         \t47        \t7         \t\n",
      "3         \t2018      \t10        \t25        \t19        \t0         \t0         \t0         \t\n",
      "4         \t2018      \t12        \t23        \t6         \t3         \t12        \t0         \t\n",
      "1         \t2019      \t6         \t13        \t7         \t2         \t6         \t3         \t\n",
      "2         \t2019      \t0         \t0         \t0         \t0         \t0         \t0         \t\n",
      "3         \t2019      \t0         \t0         \t0         \t0         \t0         \t0         \t\n",
      "4         \t2019      \t0         \t0         \t0         \t0         \t0         \t0         \t\n"
     ]
    }
   ],
   "source": [
    "create_table('../' + csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
