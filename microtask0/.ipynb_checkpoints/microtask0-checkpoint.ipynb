{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask 0\n",
    "\n",
    "## Aim:\n",
    "- Get a basic understanding of perceval and the github api data it fetches\n",
    "- Get comfortable analyzing said data: \n",
    "    - Total number of commits\n",
    "    - Number of issues and pull-requests\n",
    "    - Number of open issues and closed issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the data\n",
    "Data is collected from the atom project on github.   \n",
    "Specifically, the repositories used were:   \n",
    "- [language-java](https://github.com/atom/language-java)  \n",
    "- [teletype](https://github.com/atom/teletype)    \n",
    "The data was fetched at: \n",
    "- `2019-03-30 18:42:51` (Indian Standard Time)     \n",
    "- `2019-03-30 13:12:51` (UTC)  \n",
    "This can be fetched using the timestamp of the last row of the json file generated with perceval with the help of the `datetime.datetime.utcfromtimestamp()` method. \n",
    "\n",
    "\n",
    "### Some numbers (from the analysis in this notebook): \n",
    "**The total number of commits is**:   \n",
    "    language-java: 336  \n",
    "    teletype: 1102  \n",
    "      \n",
    "**The total number of issues is**:   \n",
    "    language-java: 96  \n",
    "    teletype: 300  \n",
    "      \n",
    "**The total number of pull-requests is**:       \n",
    "    language-java: 99  \n",
    "    teletype: 130  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Getting the data\n",
    "The cell below helps understand the data to be fetched, like the **owner**, the **repository names**, the **repository urls** and most importantly the **github authentication token**.  \n",
    "\n",
    "**Make sure to fill in your token for the `auth_token` variable in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/\"  # the github url domain: used for generating repo_urls\n",
    "owner = \"atom\"\n",
    "repos_used = [\"language-java\", \"teletype\"]\n",
    "repo_urls = [github_url + owner + \"/\" + repo_used for repo_used in repos_used]\n",
    "auth_token = \"\" # Please enter your github token here\n",
    "file_name = owner + \".json\"   # file to which perceval stores data (a ../ is automatically added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harnessing the power of jupyter notebooks\n",
    "The script in the cell below is a generalized way to create and populate a json file  using perceval.  \n",
    "\n",
    "The steps involved are simple: \n",
    "For each repository specified in the `repos_used` variable, fetch its git data, its pull_requests data and finally its issues data from the github api in that order and append them to the json file. \n",
    "\n",
    "**Note**: it has been commented to prevent an accidental overwrite of the progit.json file, present in the parent directory of our present directory. To work on more recent data, or to perform an analysis on a completely different set of repositories, please uncomment the snippet below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo, repo_url in zip(repos_used, repo_urls):\n",
    "#     print(repo, repo_url)\n",
    "\n",
    "#     !perceval git --json-line $repo_url >> ../$file_name\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category pull_request $owner $repo >> ../$file_name\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category issue $owner $repo >> ../$file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above command:\n",
    "```bash\n",
    "language-java https://github.com/atom/language-java  \n",
    "[2019-03-30 17:50:31,455] - Sir Perceval is on his quest.  \n",
    "[2019-03-30 17:50:31,457] - Fetching commits: 'https://github.com/atom/language-java' git repository from 1970-01-01 00:00:00+00:00 to 2100-01-01 00:00:00+00:00; all branches  \n",
    "[2019-03-30 17:50:35,682] - Fetch process completed: 336 commits fetched  \n",
    "[2019-03-30 17:50:35,682] - Sir Perceval completed his quest.   \n",
    "[2019-03-30 17:50:36,079] - Sir Perceval is on his quest.\n",
    "[2019-03-30 17:50:42,444] - Getting info for https://api.github.com/users/anson0370\n",
    "[2019-03-30 17:50:43,493] - Getting info for https://api.github.com/users/kevinsawicki\n",
    "[2019-03-30 17:50:46,069] - Getting info for https://api.github.com/users/tylertate\n",
    "[2019-03-30 17:50:49,013] - Getting info for https://api.github.com/users/yihangho\n",
    "..\n",
    "..\n",
    ".\n",
    "\n",
    "teletype https://github.com/atom/teletype\n",
    "[2019-03-30 17:58:41,309] - Sir Perceval is on his quest.\n",
    "[2019-03-30 17:58:51,426] - Fetching commits: 'https://github.com/atom/teletype' git repository from 1970-01-01 00:00:00+00:00 to 2100-01-01 00:00:00+00:00; all branches\n",
    "[2019-03-30 17:58:54,404] - Fetch process completed: 1102 commits fetched\n",
    "[2019-03-30 17:58:54,404] - Sir Perceval completed his quest.\n",
    "[2019-03-30 17:58:54,785] - Sir Perceval is on his quest.\n",
    "[2019-03-30 17:59:01,262] - Getting info for https://api.github.com/users/jasonrudolph\n",
    "[2019-03-30 17:59:02,550] - Getting info for https://api.github.com/users/as-cii\n",
    "[2019-03-30 17:59:11,304] - Getting info for https://api.github.com/users/simurai\n",
    "[2019-03-30 17:59:20,177] - Getting info for https://api.github.com/users/lee-dohm\n",
    "..\n",
    ".\n",
    ".\n",
    "\n",
    "[2019-03-30 18:42:44,732] - Getting info for https://api.github.com/users/joshuabrodit\n",
    "[2019-03-30 18:42:46,037] - Getting info for https://api.github.com/users/kitsune-k\n",
    "[2019-03-30 18:42:47,658] - Getting info for https://api.github.com/users/mca10\n",
    "[2019-03-30 18:42:49,088] - Getting info for https://api.github.com/users/brandon-gong\n",
    "[2019-03-30 18:42:51,247] - Sir Perceval completed his quest.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CleanJson class:\n",
    "\n",
    "This class is has been implemented as it allows for easier analysis. One thing to note here is that Perceval returns Github API data as is. The API assumes that all pull requests are considered to be issues, though the converse is not assumed to be the case. Thus, the issues fetched by perceval implicitly include the pull requests in that repository as well.\n",
    "\n",
    "To counter this, while reading the data generated by perceval, an extra condition is imposed, making it necessary for a data point with category \"issue\" to not have the \"pull_request\" key in it. \n",
    "\n",
    "This ensures that every issue is actually an issue. \n",
    "\n",
    "### Structure: \n",
    "    \n",
    "variables:\n",
    "- self.clean_data\n",
    "\n",
    "instance methods:\n",
    "- \\_\\_init__(generator)   \n",
    "    - parameters:   path_to_file  \n",
    "    - returns: None  \n",
    " \n",
    "- number_of_repos  \n",
    "    - parameters:  None  \n",
    "    - returns: int (number of repos used)  \n",
    "\n",
    "- total_commits  \n",
    "    - parameters:  None  \n",
    "    - returns: int (total_commits)  \n",
    "\n",
    "- total_commits_per_repo  \n",
    "    - parameters:   None  \n",
    "    - returns: dict  \n",
    "  \n",
    "- count_from_to   \n",
    "    - parameters:   start=None, end=None, type_of_date=\"author_date\", empty=True, merge=True  \n",
    "    - returns: int  \n",
    "        \n",
    "private methods:\n",
    "- \\_str_to_dt_data: converts string dates to a datetime object with format: \"%Y-%m-%d\"\n",
    "- \\_clean_commit: takes a line from json file and converts to a dict\n",
    "- \\_clean_issue: takes a line from json file and converts to a dict\n",
    "- \\_clean_pr: takes a line from json file and converts to a dict\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanJson:\n",
    "                \n",
    "    def __init__(self, path_to_file):\n",
    "        \n",
    "        self.clean_data = {\n",
    "            \"commit\": [], \n",
    "            \"issue\": [], \n",
    "            \"pull_request\": []\n",
    "        }\n",
    "        \n",
    "        with open(path_to_file, 'r') as raw_data:\n",
    "            for line in raw_data:\n",
    "                line = json.loads(line)\n",
    "\n",
    "                clean_line = dict()\n",
    "                if line['category'] == \"commit\":\n",
    "                    clean_line = self._clean_commit(line)\n",
    "                    \n",
    "                elif line['category'] == \"issue\":\n",
    "                    if \"pull_request\" not in line['data']:\n",
    "                        clean_line = self._clean_issue(line)\n",
    "                    else: \n",
    "                        continue\n",
    "\n",
    "                elif line['category'] == \"pull_request\":\n",
    "                    clean_line = self._clean_pr(line)\n",
    "\n",
    "                self.clean_data[line['category']].append(clean_line)        \n",
    "    \n",
    "    \n",
    "    def number_of_repos(self):\n",
    "        return len(repos_used)\n",
    "    \n",
    "    def total_commits(self):\n",
    "        return len(self.clean_data['commit'])\n",
    "    \n",
    "    def total_commits_per_repo(self):\n",
    "        commits_per_repo = {el:0 for el in repo_urls}\n",
    "        \n",
    "        for commit in self.clean_data['commit']:\n",
    "            \n",
    "            commits_per_repo[commit['repo']] += 1\n",
    "    \n",
    "        return commits_per_repo\n",
    "    \n",
    "    def count_from_to(self, start=None, end=None, type_of_date=\"author_date\", empty=True, merge=True):\n",
    "        # commit_list has elements of a specific category\n",
    "        category = \"commit\"\n",
    "        commit_list = self.clean_data[category]\n",
    "        start_date = datetime.datetime.strptime(start, \"%Y-%m-%d\") if start is not None else datetime.datetime.min\n",
    "        end_date = datetime.datetime.strptime(end, \"%Y-%m-%d\") if end is not None else datetime.datetime.max\n",
    "        \n",
    "        required_commit_set = set()\n",
    "        for elem in commit_list:\n",
    "            if start_date <= self._str_to_dt_data(elem[type_of_date]) <= end_date:\n",
    "                if (empty) or (not empty and elem['files_action'] != 0):\n",
    "                    if (merge) or (not merge and elem['merge'] == False):\n",
    "\n",
    "                        required_commit_set.add(elem['hash'])\n",
    "        return len(required_commit_set)\n",
    "                    \n",
    "    \n",
    "    # private methods to clean data ---------------------------\n",
    "    @staticmethod\n",
    "    def _str_to_dt_data(date):\n",
    "        \"\"\"\n",
    "        :param date: converts date (str) to a datetime object \n",
    "        Note: the string format for the date in the json file is either: \n",
    "         - %a %b %d %H:%M:%S %Y %z --> for commits\n",
    "         - %Y-%m-%dT%H:%M:%SZ      --> for issues and pull requests\n",
    "        \"\"\"        \n",
    "        try:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%a %b %d %H:%M:%S %Y %z\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        except ValueError as ve:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        finally:\n",
    "            datetimeobj = datetime.datetime.strptime(datetimestr, \"%Y-%m-%d\")\n",
    "            return datetimeobj\n",
    "    \n",
    "    @staticmethod                \n",
    "    def _clean_commit(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line = {\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['commit'],\n",
    "            'category': \"commit\",\n",
    "            'commit': line_data['Commit'],\n",
    "            'author': line_data['Author'],\n",
    "            'author_date': line_data['AuthorDate'],\n",
    "            'commit_date': line_data['CommitDate'],\n",
    "            'files_no': len(line_data['files'])\n",
    "        }\n",
    "        \n",
    "        # number of files affected by a commit\n",
    "        actions = 0\n",
    "        cleaned_line['files_action'] = actions\n",
    "        cleaned_line['merge'] = 'Merge' in line_data\n",
    "        \n",
    "        for file in line_data['files']:\n",
    "            if 'action' in file:\n",
    "                actions += 1\n",
    "                cleaned_line['files_action'] = actions\n",
    "                cleaned_line['merge'] = 'Merge' in line_data\n",
    "        return cleaned_line\n",
    "    \n",
    "    @staticmethod\n",
    "    def _clean_issue(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"issue\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "        return cleaned_line\n",
    "    \n",
    "    @staticmethod\n",
    "    def _clean_pr(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"pull_request\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "        return cleaned_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the data using the Class\n",
    "The cell below creates a CleanJson object `commits_data` for the file `progit.json` present in microtask0's parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CleanJson(\"../\" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of commits\n",
    "A simple use of the `total_commits()` and `total_commits_per_repo()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of commits in all repos is:  1438\n",
      "The number of commits repo-wise is: \n",
      " {'https://github.com/atom/language-java': 336, 'https://github.com/atom/teletype': 1102}\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of commits in all repos is: \", data.total_commits())\n",
    "print(\"The number of commits repo-wise is: \\n\", data.total_commits_per_repo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of commits between dates\n",
    "A simple use of the count_from_to method with different use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code changes count all period: 1438\n",
      "Code changes count from 2018-01-01 to 2018-07-01: 320\n",
      "Code changes count from 2018-01-01 to 2019-07-01 (no merge commits): 244\n"
     ]
    }
   ],
   "source": [
    "print(\"Code changes count all period:\", data.count_from_to())\n",
    "print(\"Code changes count from 2018-01-01 to 2018-07-01:\",\n",
    "      data.count_from_to(start=\"2018-01-01\", end=\"2019-07-01\"))\n",
    "print(\"Code changes count from 2018-01-01 to 2019-07-01 (no merge commits):\",\n",
    "      data.count_from_to(start=\"2018-01-01\", end=\"2018-07-01\", merge=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the json file directly\n",
    "Even without the CleanJson class, perceval makes it very easy to analyze the data produced by it. A simple context manager to read the json file line-by-line will is all that's required. \n",
    "\n",
    "As mentioned at the start, the Github API includes pull requests redundantly in the \"issue\" category, albeit with limited information. To fix that, a simple condition is employed, making sure that pull requests are not included with issues. \n",
    "\n",
    "The contents of github_data, once populated will look something like:\n",
    "\n",
    "```python\n",
    "    {\n",
    "        'commit': [commit1_dict, commit2_dict, ....], \n",
    "        'issue': [issue1_dict, issue2_dict, ....], \n",
    "        'pull_request': [pr1_dict, pr2_dict, ....], \n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_data =  {\n",
    "                \"commit\": [], \n",
    "                \"issue\": [], \n",
    "                \"pull_request\": []\n",
    "                }\n",
    "\n",
    "num_commits = 0\n",
    "with open(\"../\" + file_name, 'r') as github_data_file:\n",
    "    for line in github_data_file:\n",
    "        data_line = json.loads(line)\n",
    "        num_commits += 1\n",
    "\n",
    "        category = data_line['category']\n",
    "        if category == \"issue\":\n",
    "            if \"pull_request\" not in data_line['data']:\n",
    "                github_data[\"issue\"].append(data_line)\n",
    "            \n",
    "        else:\n",
    "            github_data[category].append(data_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of non empty commits\n",
    "Empty commits are those which do not affect any files in the repository. Thus, to count the number of such commits, we simply have to run a loop through all the commits in `github_data` and see if any files were affected by the commit. Even if one such file is found, we immediately count that commit as a non-empty one and move on to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-empty commits is:  1272\n"
     ]
    }
   ],
   "source": [
    "non_empty_commits = 0\n",
    "\n",
    "for commit in github_data['commit']:\n",
    "    for file in commit['data']['files']:\n",
    "        if 'action' in file:\n",
    "            non_empty_commits += 1\n",
    "            break\n",
    "            \n",
    "print(\"The number of non-empty commits is: \", non_empty_commits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of non - merge commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-merge commits is: 1209\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for commit in github_data['commit']:\n",
    "    if 'Merge' not in commit['data']:\n",
    "        count += 1\n",
    "        \n",
    "print(\"Number of non-merge commits is: %d\" %count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Requests and Issues\n",
    "Though commits are an important way to measure how active an organization is, pull requests and issues give a better picture of the entire community involved in that project. If you are wondering why I decided to structure `github_data` variable the way I did, you will soon realize that the part of the analysis dealing with pull requests and issues becomes so much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of pull requests and issues\n",
    "\n",
    "Lets create a dictionary `repo_wise_issues_prs`, whose structure is shown below: \n",
    "```python\n",
    "    {\n",
    "        repo_url_1: {\"issue\": .., \"pull_request\": ..}, \n",
    "        repo_url_2: {\"issue\": .., \"pull_request\": ..},\n",
    "        repo_url_3: {\"issue\": .., \"pull_request\": ..}, \n",
    "        ..\n",
    "        .\n",
    "    }\n",
    "```\n",
    "The generic keys used allow this part of the script to work no matter which repositories or projects are used for the analysis.\n",
    "\n",
    "Looping through each issue and pull request in `github_data`, simply populate `repo_wise_issues_prs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"https://github.com/atom/language-java\": {\n",
      "        \"issue\": 96,\n",
      "        \"pull_request\": 99\n",
      "    },\n",
      "    \"https://github.com/atom/teletype\": {\n",
      "        \"issue\": 300,\n",
      "        \"pull_request\": 130\n",
      "    }\n",
      "}\n",
      "Total number of issues:  396\n",
      "Total number of pull requests:  229\n"
     ]
    }
   ],
   "source": [
    "repo_wise_issues_prs = {repo_url: {\"issue\": 0, \"pull_request\": 0} for repo_url in repo_urls}\n",
    "total_issues = 0\n",
    "total_prs = 0\n",
    "\n",
    "for elem in github_data['issue']:\n",
    "    repo_wise_issues_prs[elem['origin']]['issue'] += 1\n",
    "    total_issues += 1\n",
    "    \n",
    "for elem in github_data['pull_request']:\n",
    "    repo_wise_issues_prs[elem['origin']]['pull_request'] += 1\n",
    "    total_prs += 1\n",
    "\n",
    "print(json.dumps(repo_wise_issues_prs, indent=4))\n",
    "print(\"Total number of issues: \", total_issues)\n",
    "print(\"Total number of pull requests: \", total_prs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of open and closed issues\n",
    "From the results in the previous cell i.e the total number of issues, we can check the number of open and closed issues. Though the number of open issues can be correlated with inactivity, this is not always the case as certain issues pertaining to specific project topics are more useful when open and when people can actively add comments in that issue  --- a good example being that of the issues for GSOC ideas.\n",
    "\n",
    "Thus, the cell below simply analyses the `status` key of each issue. Of course, it is easy to lose track of things when so many features and dimensions are involved. \n",
    "To reiterate: \n",
    "```python\n",
    "github_data = {\n",
    "    \"commit\": [commit1_dict1, commit2_dict, ..],\n",
    "    \"issue\": [issue1_dict1, issue2_dict, ..],\n",
    "    \"pull_request\": [pull_request1_dict1, pull_request2_dict, ..]\n",
    "}\n",
    "```\n",
    "\n",
    "Coming back to the analysis, if the 'state' of an issue is open, we increment the `num_open_issues` counter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of open issues is  82\n",
      "The number of closed issues is  314\n"
     ]
    }
   ],
   "source": [
    "num_open_issues = 0\n",
    "for issue in github_data[\"issue\"]:\n",
    "    if issue['data']['state'] == \"open\":\n",
    "        num_open_issues += 1\n",
    "        \n",
    "print(\"The number of open issues is \", num_open_issues)\n",
    "print(\"The number of closed issues is \", total_issues - num_open_issues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
