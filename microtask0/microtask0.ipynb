{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask 0\n",
    "\n",
    "## Aim:\n",
    "- Get a basic understanding of perceval and the github api data it fetches\n",
    "- Get comfortable analyzing said data: \n",
    "    - Total number of commits\n",
    "    - Number of issues and pull-requests\n",
    "    - Number of open issues and closed issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the data\n",
    "Data is collected from the progit project on github. \n",
    "Specifically, the repositories used were: \n",
    "- [progit2-ru](https://github.com/progit/progit2-ru)\n",
    "- [progit2-zh](https://github.com/progit/progit2-zh) were used.  \n",
    "The data was fetched at: `Wednesday 20 March 2019 05∶52∶27 PM IST`\n",
    "\n",
    "### Some numbers (from the analysis in this notebook): \n",
    "**The total number of commits is**:   \n",
    "    progit2-ru: 1292  \n",
    "    progit2-zh: 1792  \n",
    "      \n",
    "**The total number of issues is**:   \n",
    "    progit2-ru: 218  \n",
    "    progit2-zh: 366  \n",
    "      \n",
    "**The total number of pull-requests is**:       \n",
    "    progit2-ru: 218  \n",
    "    progit2-zh: 258  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Getting the data\n",
    "The cell below helps understand the data to be fetched, like the **owner**, the **repository names**, the **repository urls** and most importantly the **github authentication token**.  \n",
    "\n",
    "**Make sure to fill in your token for the `auth_token` variable in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/\"  # the github url domain: used for generating repo_urls\n",
    "owner = \"progit\"\n",
    "repos_used = [\"progit2-ru\", \"progit2-zh\"]\n",
    "repo_urls = [github_url + owner + \"/\" + repo_used for repo_used in repos_used]\n",
    "auth_token = \"\" # Please enter your github token here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harnessing the power of jupyter notebooks, the script in the cell below is a generalized way to create and populate a file named `progit.json`  using perceval.  \n",
    "\n",
    "The steps involved are simple: \n",
    "For each repository specified in the `repos_used` variable, fetch its git data, its pull_requests data and finally its issues data from the github api in that order and append them to `progit.json`. \n",
    "\n",
    "**Note**: it has been commented to prevent an accidental overwrite of the progit.json file, present in the parent directory of our present directory. To work on more recent data, or to perform an analysis on a completely different set of repositories, please uncomment the snippet below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo, repo_url in zip(repos_used, repo_urls):\n",
    "#     print(repo, repo_url)\n",
    "#     if repo == repos_used[0]:\n",
    "#         !perceval git --json-line $repo_url > ../progit.json\n",
    "\n",
    "#     else:\n",
    "#         !perceval git --json-line $repo_url >> ../progit.json\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category pull_request $owner $repo >> ../progit.json\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category issue $owner $repo >> ../progit.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CleanJson class:\n",
    "\n",
    "### Structure: \n",
    "    \n",
    "variables:\n",
    "- self.clean_data\n",
    "\n",
    "instance methods:\n",
    "- \\_\\_init__(generator)   \n",
    "    - parameters:   path_to_file  \n",
    "    - returns: None  \n",
    " \n",
    "- number_of_repos  \n",
    "    - parameters:  None  \n",
    "    - returns: int (number of repos used)  \n",
    "\n",
    "- total_commits  \n",
    "    - parameters:  None  \n",
    "    - returns: int (total_commits)  \n",
    "\n",
    "- total_commits_per_repo  \n",
    "    - parameters:   None  \n",
    "    - returns: dict  \n",
    "  \n",
    "- count_from_to   \n",
    "    - parameters:   start=None, end=None, type_of_date=\"author_date\", empty=True, merge=True  \n",
    "    - returns: int  \n",
    "        \n",
    "private methods:\n",
    "- \\_str_to_dt_data: converts string dates to a datetime object with format: \"%Y-%m-%d\"\n",
    "- \\_clean_commit: takes a line from json file and converts to a dict\n",
    "- \\_clean_issue: takes a line from json file and converts to a dict\n",
    "- \\_clean_pr: takes a line from json file and converts to a dict\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanJson:\n",
    "                \n",
    "    def __init__(self, path_to_file):\n",
    "        \n",
    "        self.clean_data = {\n",
    "            \"commit\": [], \n",
    "            \"issue\": [], \n",
    "            \"pull_request\": []\n",
    "        }\n",
    "        \n",
    "        with open(path_to_file, 'r') as raw_data:\n",
    "            for line in raw_data:\n",
    "                line = json.loads(line)\n",
    "\n",
    "                clean_line = dict()\n",
    "                if line['category'] == \"commit\":\n",
    "                    clean_line = self._clean_commit(line)\n",
    "                    \n",
    "                elif line['category'] == \"issue\":\n",
    "                    clean_line = self._clean_issue(line)\n",
    "\n",
    "                elif line['category'] == \"pull_request\":\n",
    "                    clean_line = self._clean_pr(line)\n",
    "\n",
    "                self.clean_data[line['category']].append(clean_line)        \n",
    "    \n",
    "    \n",
    "    def number_of_repos(self):\n",
    "        return len(repos_used)\n",
    "    \n",
    "    def total_commits(self):\n",
    "        return len(self.clean_data['commit'])\n",
    "    \n",
    "    def total_commits_per_repo(self):\n",
    "        commits_per_repo = {el:0 for el in repo_urls}\n",
    "        \n",
    "        for commit in self.clean_data['commit']:\n",
    "            \n",
    "            commits_per_repo[commit['repo']] += 1\n",
    "    \n",
    "        return commits_per_repo\n",
    "    \n",
    "    def count_from_to(self, start=None, end=None, type_of_date=\"author_date\", empty=True, merge=True):\n",
    "        # commit_list has elements of a specific category\n",
    "        category = \"commit\"\n",
    "        commit_list = self.clean_data[category]\n",
    "        start_date = datetime.datetime.strptime(start, \"%Y-%m-%d\") if start is not None else datetime.datetime.min\n",
    "        end_date = datetime.datetime.strptime(end, \"%Y-%m-%d\") if end is not None else datetime.datetime.max\n",
    "        \n",
    "        required_commit_set = set()\n",
    "        for elem in commit_list:\n",
    "            if start_date <= self._str_to_dt_data(elem[type_of_date]) <= end_date:\n",
    "                if (empty) or (not empty and elem['files_action'] != 0):\n",
    "                    if (merge) or (not merge and elem['merge'] == False):\n",
    "\n",
    "                        required_commit_set.add(elem['hash'])\n",
    "        return len(required_commit_set)\n",
    "                    \n",
    "    \n",
    "    # private methods to clean data ---------------------------\n",
    "    @staticmethod\n",
    "    def _str_to_dt_data(date):\n",
    "        \"\"\"\n",
    "        :param date: converts date (str) to a datetime object \n",
    "        Note: the string format for the date in the json file is either: \n",
    "         - %a %b %d %H:%M:%S %Y %z --> for commits\n",
    "         - %Y-%m-%dT%H:%M:%SZ      --> for issues and pull requests\n",
    "        \"\"\"        \n",
    "        try:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%a %b %d %H:%M:%S %Y %z\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        except ValueError as ve:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        finally:\n",
    "            datetimeobj = datetime.datetime.strptime(datetimestr, \"%Y-%m-%d\")\n",
    "            return datetimeobj\n",
    "    \n",
    "    @staticmethod                \n",
    "    def _clean_commit(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line = {\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['commit'],\n",
    "            'category': \"commit\",\n",
    "            'commit': line_data['Commit'],\n",
    "            'author': line_data['Author'],\n",
    "            'author_date': line_data['AuthorDate'],\n",
    "            'commit_date': line_data['CommitDate'],\n",
    "            'files_no': len(line_data['files'])\n",
    "        }\n",
    "        \n",
    "        # number of files affected by a commit\n",
    "        actions = 0\n",
    "        cleaned_line['files_action'] = actions\n",
    "        cleaned_line['merge'] = 'Merge' in line_data\n",
    "        \n",
    "        for file in line_data['files']:\n",
    "            if 'action' in file:\n",
    "                actions += 1\n",
    "                cleaned_line['files_action'] = actions\n",
    "                cleaned_line['merge'] = 'Merge' in line_data\n",
    "        return cleaned_line\n",
    "    \n",
    "    @staticmethod\n",
    "    def _clean_issue(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"issue\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "        return cleaned_line\n",
    "    \n",
    "    @staticmethod\n",
    "    def _clean_pr(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"pull_request\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "        return cleaned_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the data using the Class\n",
    "The cell below creates a CleanJson object `commits_data` for the file `progit.json` present in microtask0's parent directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CleanJson('../progit.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of commits\n",
    "A simple use of the `total_commits()` and `total_commits_per_repo()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of commits in all repos is:  3024\n",
      "The number of commits repo-wise is: \n",
      " {'https://github.com/progit/progit2-ru': 1292, 'https://github.com/progit/progit2-zh': 1732}\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of commits in all repos is: \", data.total_commits())\n",
    "print(\"The number of commits repo-wise is: \\n\", data.total_commits_per_repo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of commits between dates\n",
    "A simple use of the count_from_to method with different use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code changes count all period: 2402\n",
      "Code changes count from 2018-01-01 to 2018-07-01: 77\n",
      "Code changes count from 2018-01-01 to 2019-07-01 (no merge commits): 27\n"
     ]
    }
   ],
   "source": [
    "print(\"Code changes count all period:\", data.count_from_to())\n",
    "print(\"Code changes count from 2018-01-01 to 2018-07-01:\",\n",
    "      data.count_from_to(start=\"2018-01-01\", end=\"2019-07-01\"))\n",
    "print(\"Code changes count from 2018-01-01 to 2019-07-01 (no merge commits):\",\n",
    "      data.count_from_to(start=\"2018-01-01\", end=\"2018-07-01\", merge=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the json file directly\n",
    "Even without the CleanJson class, perceval makes it very easy to analyze the data produced by it. A simple context manager to read the json file line-by-line will is all that's required.\n",
    "\n",
    "The contents of github_data will once populated will look something like:\n",
    "\n",
    "```python\n",
    "    {\n",
    "        'commit': [commit1_dict, commit2_dict, ....], \n",
    "        'issue': [issue1_dict, issue2_dict, ....], \n",
    "        'pull_request': [pr1_dict, pr2_dict, ....], \n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_data =  {\n",
    "                \"commit\": [], \n",
    "                \"issue\": [], \n",
    "                \"pull_request\": []\n",
    "                }\n",
    "\n",
    "num_commits = 0\n",
    "with open('../../progit.json', 'r') as github_data_file:\n",
    "    for line in github_data_file:\n",
    "        data_line = json.loads(line)\n",
    "        num_commits += 1\n",
    "\n",
    "        category = data_line['category']\n",
    "        github_data[category].append(data_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of non empty commits\n",
    "Empty commits are those which do not affect any files in the repository. Thus, to count the number of such commits, we simply have to run a loop through all the commits in `github_data` and see if any files were affected by the commit. Even if one such file is found, we immediately count that commit as a non-empty one and move on to the next one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610\n"
     ]
    }
   ],
   "source": [
    "non_empty_commits = 0\n",
    "\n",
    "for commit in github_data['commit']:\n",
    "    for file in commit['data']['files']:\n",
    "        if 'action' in file:\n",
    "            non_empty_commits += 1\n",
    "            break\n",
    "            \n",
    "print(non_empty_commits)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of non - merge commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-merge commits is: 2453\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for commit in github_data['commit']:\n",
    "    if 'Merge' not in commit['data']:\n",
    "        count += 1\n",
    "        \n",
    "print(\"Number of non-merge commits is: %d\" %count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Requests and Issues\n",
    "Though commits are an important way to measure how active an organization is, pull requests and issues give a better picture of the entire community involved in that project. If you are wondering why I decided to structure `github_data` variable the way I did, you will soon realize that the part of the analysis dealing with pull requests and issues becomes so much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of pull requests and issues\n",
    "\n",
    "Lets create a dictionary `repo_wise_issues_prs`, whose structure is shown below: \n",
    "```python\n",
    "    {\n",
    "        repo_url_1: {\"issue\": .., \"pull_request\": ..}, \n",
    "        repo_url_2: {\"issue\": .., \"pull_request\": ..},\n",
    "        repo_url_3: {\"issue\": .., \"pull_request\": ..}, \n",
    "        ..\n",
    "        .\n",
    "    }\n",
    "```\n",
    "The generic keys used allow this part of the script to work no matter which repositories or projects are used for the analysis.\n",
    "\n",
    "Looping through each issue and pull request in `github_data`, simply populate `repo_wise_issues_prs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"https://github.com/progit/progit2-ru\": {\n",
      "        \"issue\": 218,\n",
      "        \"pull_request\": 200\n",
      "    },\n",
      "    \"https://github.com/progit/progit2-zh\": {\n",
      "        \"issue\": 366,\n",
      "        \"pull_request\": 258\n",
      "    }\n",
      "}\n",
      "Total number of issues:  584\n",
      "Total number of pull requests:  458\n"
     ]
    }
   ],
   "source": [
    "repo_wise_issues_prs = {repo_url: {\"issue\": 0, \"pull_request\": 0} for repo_url in repo_urls}\n",
    "total_issues = 0\n",
    "total_prs = 0\n",
    "\n",
    "for elem in github_data['issue']:\n",
    "    repo_wise_issues_prs[elem['origin']]['issue'] += 1\n",
    "    total_issues += 1\n",
    "    \n",
    "for elem in github_data['pull_request']:\n",
    "    repo_wise_issues_prs[elem['origin']]['pull_request'] += 1\n",
    "    total_prs += 1\n",
    "\n",
    "print(json.dumps(repo_wise_issues_prs, indent=4))\n",
    "print(\"Total number of issues: \", total_issues)\n",
    "print(\"Total number of pull requests: \", total_prs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of open and closed issues\n",
    "From the results in the previous cell i.e the total number of issues, we can check the number of open and closed issues. Though the number of open issues can be correlated with inactivity, this is not always the case as certain issues pertaining to specific project topics are more useful when open and when people can actively add comments in that issue  --- a good example being that of the issues for GSOC ideas.\n",
    "\n",
    "Thus, the cell below simply analyses the `status` key of each issue. Of course, it is easy to lose track of things when so many features and dimensions are involved. \n",
    "To reiterate: \n",
    "```python\n",
    "github_data = {\n",
    "    \"commit\": [commit1_dict1, commit2_dict, ..],\n",
    "    \"issue\": [issue1_dict1, issue2_dict, ..],\n",
    "    \"pull_request\": [pull_request1_dict1, pull_request2_dict, ..]\n",
    "}\n",
    "```\n",
    "\n",
    "Coming back to the analysis, if the 'state' of an issue is open, we increment the `num_open_issues` counter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of open issues is  32\n",
      "The number of closed issues is  552\n"
     ]
    }
   ],
   "source": [
    "num_open_issues = 0\n",
    "for issue in github_data[\"issue\"]:\n",
    "    if issue['data']['state'] == \"open\":\n",
    "        num_open_issues += 1\n",
    "        \n",
    "print(\"The number of open issues is \", num_open_issues)\n",
    "print(\"The number of closed issues is \", total_issues - num_open_issues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
