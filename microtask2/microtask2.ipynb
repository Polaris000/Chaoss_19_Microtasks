{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask 2\n",
    "\n",
    "## Aim of the task: \n",
    "Analysis of data fetched by perceval on a per-quarter basis.\n",
    "This includes (but not limited to) :\n",
    "\n",
    "- The number of new committers per quarter\n",
    "- The number of new issue and pull request submitters per quarter\n",
    "- The total number of issues, commits and pull requests per quarter\n",
    "\n",
    "This task is exactly the same as microtask 1, except for the fact that this one is supposed to be done using pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Getting the data\n",
    "The data used for this microtask is the same as that used for the previous microtasks. Please check microtask 0 to see the cell output generated by running the commented script present two cells below this one. \n",
    "The cell below helps understand the data to be fetched, like the **owner**, the **repository names**, the **repository urls** and most importantly the **github authentication token**.  \n",
    "\n",
    "**Make sure to fill in your token for the `auth_token` variable in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/\"  # the github url domain: used for generating repo_urls\n",
    "owner = \"atom\"\n",
    "repos_used = [\"language-java\", \"teletype\"]\n",
    "repo_urls = [github_url + owner + \"/\" + repo_used for repo_used in repos_used]\n",
    "auth_token = \"\" # Please enter your github token here\n",
    "file_name = owner + \".json\" # file to which perceval stores data (a ../ is automatically added)\n",
    "csv_name = owner + \".csv\" # file to which csv data is written (a ../ is automatically added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harnessing the power of jupyter notebooks \n",
    "The script in the cell below is a generalized way to create and populate a json file using perceval.  \n",
    "\n",
    "The steps involved are simple: \n",
    "For each repository specified in the `repos_used` variable, fetch its git data, its pull_requests data and finally its issues data from the github api in that order and append them to the json file. \n",
    "\n",
    "**Note**: it has been commented out to prevent an accidental overwrite of the json file, present in the parent directory of our present directory. To work on more recent data, or to perform an analysis on a completely different set of repositories (make sure to change the variables in the cell above), please uncomment the snippet below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo, repo_url in zip(repos_used, repo_urls):\n",
    "#     print(repo, repo_url)\n",
    "\n",
    "#     !perceval git --json-line $repo_url >> ../$file_name\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category pull_request $owner $repo >> ../$file_name\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category issue $owner $repo >> ../$file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a few constants\n",
    "**start_year and end_year**:\n",
    "    these denote the range of quarters we'll be considering. For example, the current usage implies that 12 quarters will be considered for this metric. Thus, the end_year will be considered. The date ranges for the quarters have been fixed and stored in dictionaries as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here both start year and end year are included\n",
    "start_year = 2017\n",
    "end_year = 2019 \n",
    "\n",
    "quar1_dates = {\"start_date\": \"01-01\", \"end_date\": \"03-31\"}\n",
    "quar2_dates = {\"start_date\": \"04-01\", \"end_date\": \"06-30\"}\n",
    "quar3_dates = {\"start_date\": \"07-01\", \"end_date\": \"09-30\"}\n",
    "quar4_dates = {\"start_date\": \"10-01\", \"end_date\": \"12-31\"}\n",
    "\n",
    "old_committers = set()\n",
    "old_issue_subs = set()\n",
    "old_pr_subs = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Quarter class\n",
    "I was looking for an easy way to represent the collected data. I went with a class representation of a quarter so that when the time comes to analyze data per quarter, all that's left to be done is to use the instance variables of that quarter object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quarter:\n",
    "    \n",
    "    def __init__(self, number, year):\n",
    "        self.number = number    \n",
    "        self.year = year   \n",
    "   \n",
    "        self.num_commits = 0  \n",
    "        self.num_issues = 0\n",
    "        self.num_pullrequests = 0\n",
    "        \n",
    "        self.new_committers = 0\n",
    "        self.new_issue_subs = 0\n",
    "        self.new_pr_subs = 0\n",
    "        \n",
    "        self.start_date = \"\"\n",
    "        self.end_date = \"\"\n",
    "        \n",
    "        if self.number == 1:\n",
    "            self.start_date = str(self.year) + '-' + quar1_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar1_dates[\"end_date\"]\n",
    "            \n",
    "        if self.number == 2:\n",
    "            self.start_date = str(self.year) + '-' + quar2_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar3_dates[\"end_date\"]            \n",
    "            \n",
    "        if self.number == 3:\n",
    "            self.start_date = str(self.year) + '-' + quar3_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar3_dates[\"end_date\"]\n",
    "            \n",
    "        if self.number == 4:\n",
    "            self.start_date = str(self.year) + '-' + quar4_dates[\"start_date\"]\n",
    "            self.end_date = str(self.year) + '-' + quar4_dates[\"end_date\"]\n",
    "        \n",
    "            \n",
    "    def is_includes_data(self, date):\n",
    "        if self._str_to_dt_quarter(self.start_date) <= self._str_to_dt_data(date) < self._str_to_dt_quarter(self.end_date):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def add_analysis(self, datapoint):\n",
    "        if datapoint['category'] == \"commit\":\n",
    "            self.num_commits += 1 \n",
    "            \n",
    "            if datapoint['author'] not in old_committers:\n",
    "                self.new_committers += 1\n",
    "                \n",
    "            old_committers.add(datapoint['author'])\n",
    "            \n",
    "                \n",
    "        if datapoint['category'] == \"issue\":\n",
    "            self.num_issues += 1 \n",
    "            \n",
    "            if datapoint['author'] not in old_issue_subs:\n",
    "                self.new_issue_subs += 1\n",
    "                \n",
    "            old_issue_subs.add(datapoint['author'])\n",
    "            \n",
    "                \n",
    "        if datapoint['category'] == \"pull_request\":\n",
    "            self.num_pullrequests += 1 \n",
    "            \n",
    "            if datapoint['author'] not in old_pr_subs:\n",
    "                self.new_pr_subs += 1\n",
    "                \n",
    "            old_pr_subs.add(datapoint['author'])\n",
    "    \n",
    "    @staticmethod\n",
    "    def _str_to_dt_data(date):\n",
    "        try:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%a %b %d %H:%M:%S %Y %z\").strftime(\"%Y-%m-%d\")\n",
    "            \n",
    "        \n",
    "        except ValueError as ve:\n",
    "            datetimestr =  datetime.datetime.strptime(date, \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        finally:\n",
    "            datetimeobj = datetime.datetime.strptime(datetimestr, \"%Y-%m-%d\")\n",
    "            return datetimeobj    \n",
    "        \n",
    "    @staticmethod\n",
    "    def _str_to_dt_quarter(date):\n",
    "        \n",
    "        datetimeobj =  datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        return datetimeobj\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.number) + \" \" + str(self.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Organizing the Data\n",
    "The CleanJson class is just like the one used in microtask 1, the only difference being that each item (commit, pull_request or issue) is a row in the corresponding dataframe. \n",
    "Thus, \n",
    "    - clean_commit_df : Each row is a commit\n",
    "    - clean_issue_df: Each row is an issue\n",
    "    - clean_pr_df: Each row is a pull request\n",
    "    \n",
    "A dictionary `clean_dict` with the keys \"commit\", \"issue\" and \"pull_request\" is another member of the CleanJson class. The corresponding values of its keys are the dataframes mentioned above.\n",
    "Thus, the overall structure is:\n",
    "```python\n",
    "    clean_dict = {\n",
    "        \"commit\": clean_commit_df,\n",
    "        \"issue\": clean_issue_df,\n",
    "        \"pull_request\": clean_pr_df\n",
    "    }\n",
    "```\n",
    "\n",
    "Note: in the \\_\\_init\\_\\_ method, you might notice that there is an extra condition for when the category of the data is \"issue\". As mentioned in previous microtasks, the Github API assumes that all pull requests are issues as well, and hence, redundant pull request data is present in the \"issue\" category. \n",
    "The extra condition counters that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanJson():   \n",
    "    \n",
    "    def __init__(self, path_to_file):\n",
    "\n",
    "        # The dataframes mentioned in the above cell will be populated using the \n",
    "        # following lists: pd.DataFrame(list_name)\n",
    "        clean_commit_list = list()\n",
    "        clean_issue_list = list()\n",
    "        clean_pr_list = list()\n",
    "        \n",
    "        with open(path_to_file, 'r') as raw_data:\n",
    "            for line in raw_data:\n",
    "                line = json.loads(line)\n",
    "                \n",
    "                clean_line = dict()\n",
    "                if line['category'] == \"commit\":\n",
    "                    clean_line = self._clean_commit(line)\n",
    "                    clean_commit_list.append(clean_line)\n",
    "                    \n",
    "\n",
    "                elif line['category'] == \"issue\":\n",
    "                    if \"pull_request\" not in line['data']:\n",
    "                        clean_line = self._clean_issue(line)\n",
    "                        clean_issue_list.append(clean_line)\n",
    "                    else: continue\n",
    "                    \n",
    "\n",
    "                elif line['category'] == \"pull_request\":\n",
    "                    clean_line = self._clean_pr(line)\n",
    "                    clean_pr_list.append(clean_line)\n",
    "                        \n",
    "                        \n",
    "                self.clean_commit_df = pd.DataFrame(clean_commit_list)\n",
    "                self.clean_issue_df = pd.DataFrame(clean_issue_list)\n",
    "                self.clean_pr_df = pd.DataFrame(clean_pr_list)\n",
    "                \n",
    "            self.clean_dict = {\n",
    "                'commit': self.clean_commit_df,\n",
    "                'issue': self.clean_issue_df,\n",
    "                'pull_request': self.clean_pr_df\n",
    "            }\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_commit(line):\n",
    "            repo_name = line['origin']\n",
    "            line_data = line['data']\n",
    "            cleaned_line = {\n",
    "                'repo': repo_name,\n",
    "                'hash': line_data['commit'],\n",
    "                'category': \"commit\",\n",
    "                'commit': line_data['Commit'],\n",
    "                'author': line_data['Author'],\n",
    "                'created_date': line_data['CommitDate'],\n",
    "                'files_no': len(line_data['files'])\n",
    "            }\n",
    "\n",
    "            actions = 0\n",
    "\n",
    "            for file in line_data['files']:\n",
    "                if 'action' in file:\n",
    "                    actions += 1\n",
    "                    cleaned_line['files_action'] = actions\n",
    "                    cleaned_line['merge'] = 'Merge' in line_data\n",
    "            return cleaned_line\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_issue(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"issue\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "\n",
    "        return cleaned_line\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_pr(line):\n",
    "        repo_name = line['origin']\n",
    "        line_data = line['data']\n",
    "        cleaned_line ={\n",
    "            'repo': repo_name,\n",
    "            'hash': line_data['id'],\n",
    "            'category': \"pull_request\",\n",
    "            'author': line_data['user']['login'],\n",
    "            'created_date': line_data['created_at'],\n",
    "            'current_status': line_data['state']   \n",
    "        }\n",
    "\n",
    "        return cleaned_line\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Quarter object\n",
    "Again, this step is exactly the same as microtask 1, where, based on the `start_year` and `end_year` variables in the third cell of this notebook, quarters are created. Be sure to note that even the `end_year` is included:\n",
    "    For example, if `start_year` is 2017 and `end_year` is 2018, 8 quarters will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = [x for x in range(start_year, end_year + 1)]\n",
    "quar_list = [Quarter(num, year)  for year in year_list for num in range(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = CleanJson('../' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in clean_data.clean_dict.values():\n",
    "    data = df\n",
    "    for quarter in quar_list:\n",
    "        \n",
    "        for index, data_point in data.iterrows():\n",
    "            \n",
    "            data_point = pd.Series.to_dict(data_point)\n",
    "            if quarter.is_includes_data(data_point[\"created_date\"]):\n",
    "                quarter.add_analysis(data_point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of commits, pull requests and issues per quadrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter num and year:  1 2017  \n",
      " commits:  14  \n",
      " issues:  2  \n",
      " pull requests:  6\n",
      "--------------------------------\n",
      "Quarter num and year:  2 2017  \n",
      " commits:  373  \n",
      " issues:  79  \n",
      " pull requests:  40\n",
      "--------------------------------\n",
      "Quarter num and year:  3 2017  \n",
      " commits:  267  \n",
      " issues:  60  \n",
      " pull requests:  32\n",
      "--------------------------------\n",
      "Quarter num and year:  4 2017  \n",
      " commits:  521  \n",
      " issues:  146  \n",
      " pull requests:  67\n",
      "--------------------------------\n",
      "Quarter num and year:  1 2018  \n",
      " commits:  215  \n",
      " issues:  38  \n",
      " pull requests:  35\n",
      "--------------------------------\n",
      "Quarter num and year:  2 2018  \n",
      " commits:  87  \n",
      " issues:  62  \n",
      " pull requests:  27\n",
      "--------------------------------\n",
      "Quarter num and year:  3 2018  \n",
      " commits:  10  \n",
      " issues:  25  \n",
      " pull requests:  19\n",
      "--------------------------------\n",
      "Quarter num and year:  4 2018  \n",
      " commits:  12  \n",
      " issues:  23  \n",
      " pull requests:  6\n",
      "--------------------------------\n",
      "Quarter num and year:  1 2019  \n",
      " commits:  6  \n",
      " issues:  13  \n",
      " pull requests:  7\n",
      "--------------------------------\n",
      "Quarter num and year:  2 2019  \n",
      " commits:  0  \n",
      " issues:  0  \n",
      " pull requests:  0\n",
      "--------------------------------\n",
      "Quarter num and year:  3 2019  \n",
      " commits:  0  \n",
      " issues:  0  \n",
      " pull requests:  0\n",
      "--------------------------------\n",
      "Quarter num and year:  4 2019  \n",
      " commits:  0  \n",
      " issues:  0  \n",
      " pull requests:  0\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "for q in quar_list:\n",
    "    print(\"Quarter num and year: \" ,q,    \n",
    "          \" \\n commits: \", q.num_commits,\n",
    "          \" \\n issues: \", q.num_issues, \n",
    "          \" \\n pull requests: \", q.num_pullrequests)\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of new committers, new issue submitters and pull request creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarter num and year:  1 2017  \n",
      " new committers:  2  \n",
      " new issue submitters:  2  \n",
      " new pull request creators:  2\n",
      "-----------------------------------\n",
      "Quarter num and year:  2 2017  \n",
      " new committers:  9  \n",
      " new issue submitters:  23  \n",
      " new pull request creators:  6\n",
      "-----------------------------------\n",
      "Quarter num and year:  3 2017  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "-----------------------------------\n",
      "Quarter num and year:  4 2017  \n",
      " new committers:  7  \n",
      " new issue submitters:  74  \n",
      " new pull request creators:  5\n",
      "-----------------------------------\n",
      "Quarter num and year:  1 2018  \n",
      " new committers:  8  \n",
      " new issue submitters:  28  \n",
      " new pull request creators:  6\n",
      "-----------------------------------\n",
      "Quarter num and year:  2 2018  \n",
      " new committers:  5  \n",
      " new issue submitters:  47  \n",
      " new pull request creators:  7\n",
      "-----------------------------------\n",
      "Quarter num and year:  3 2018  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "-----------------------------------\n",
      "Quarter num and year:  4 2018  \n",
      " new committers:  3  \n",
      " new issue submitters:  12  \n",
      " new pull request creators:  0\n",
      "-----------------------------------\n",
      "Quarter num and year:  1 2019  \n",
      " new committers:  2  \n",
      " new issue submitters:  6  \n",
      " new pull request creators:  3\n",
      "-----------------------------------\n",
      "Quarter num and year:  2 2019  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "-----------------------------------\n",
      "Quarter num and year:  3 2019  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "-----------------------------------\n",
      "Quarter num and year:  4 2019  \n",
      " new committers:  0  \n",
      " new issue submitters:  0  \n",
      " new pull request creators:  0\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for q in quar_list:\n",
    "    print(\"Quarter num and year: \" ,q,    \n",
    "          \" \\n new committers: \", q.new_committers,\n",
    "          \" \\n new issue submitters: \", q.new_issue_subs, \n",
    "          \" \\n new pull request creators: \", q.new_pr_subs)\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing data as a csv file\n",
    "This part is almost completely the same as microtask 1, except for the part where a table is created using the csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the cleaned data to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(file_path):\n",
    "    with open(file_path, 'w', ) as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "        \n",
    "        file_headers = [\"Quarter(Num)\", \"Quarter(Year)\", \"Num_Commits\", \"Num_Issues\", \"Num_PRs\", \"Num_new_commits\", \"Num_new_issues\", \"Num_new_prs\"]\n",
    "        csv_writer.writerow(file_headers)\n",
    "        \n",
    "        for quar in quar_list:\n",
    "            row = [str(quar.number),         \\\n",
    "                 str(quar.year),             \\\n",
    "                 str(quar.num_commits) ,     \\\n",
    "                 str(quar.num_issues)  ,     \\\n",
    "                 str(quar.num_pullrequests), \\\n",
    "                 str(quar.new_committers),   \\\n",
    "                 str(quar.new_issue_subs),   \\\n",
    "                 str(quar.new_pr_subs)       \n",
    "                  ]\n",
    "            csv_writer.writerow(x for x in row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(\"../\" + csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying a table based on the csv file\n",
    "Instead of the csv.reader used in microtask1, the `pandas.read_csv()` is used to populate a dataframe, which is displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter(Num)</th>\n",
       "      <th>Quarter(Year)</th>\n",
       "      <th>Num_Commits</th>\n",
       "      <th>Num_Issues</th>\n",
       "      <th>Num_PRs</th>\n",
       "      <th>Num_new_commits</th>\n",
       "      <th>Num_new_issues</th>\n",
       "      <th>Num_new_prs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>373</td>\n",
       "      <td>79</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>267</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>521</td>\n",
       "      <td>146</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>215</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>87</td>\n",
       "      <td>62</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter(Num)  Quarter(Year)  Num_Commits  Num_Issues  Num_PRs  \\\n",
       "0              1           2017           14           2        6   \n",
       "1              2           2017          373          79       40   \n",
       "2              3           2017          267          60       32   \n",
       "3              4           2017          521         146       67   \n",
       "4              1           2018          215          38       35   \n",
       "5              2           2018           87          62       27   \n",
       "6              3           2018           10          25       19   \n",
       "7              4           2018           12          23        6   \n",
       "8              1           2019            6          13        7   \n",
       "9              2           2019            0           0        0   \n",
       "10             3           2019            0           0        0   \n",
       "11             4           2019            0           0        0   \n",
       "\n",
       "    Num_new_commits  Num_new_issues  Num_new_prs  \n",
       "0                 2               2            2  \n",
       "1                 9              23            6  \n",
       "2                 0               0            0  \n",
       "3                 7              74            5  \n",
       "4                 8              28            6  \n",
       "5                 5              47            7  \n",
       "6                 0               0            0  \n",
       "7                 3              12            0  \n",
       "8                 2               6            3  \n",
       "9                 0               0            0  \n",
       "10                0               0            0  \n",
       "11                0               0            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../' + csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
