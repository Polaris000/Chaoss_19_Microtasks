{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask 0\n",
    "\n",
    "## Aim:\n",
    "- Get a basic understanding of perceval and the github api data it fetches\n",
    "- Get comfortable analyzing said data: \n",
    "    - Total number of commits\n",
    "    - Number of issues and pull-requests\n",
    "    - Number of open issues and closed issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Getting the data\n",
    "The cell below helps understand the data to be fetched, like the **owner**, the **repository names**, the **repository urls** and most importantly the **github authentication token**.  \n",
    "\n",
    "**Make sure to fill in your token for the `auth_token` variable in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/\"  # the github url domain: used for generating repo_urls\n",
    "owner = \"progit\"\n",
    "repos_used = [\"progit2-ru\", \"progit2-zh\"]\n",
    "repo_urls = [github_url + owner + \"/\" + repo_used for repo_used in repos_used]\n",
    "auth_token = \"\" # Please enter your github token here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harnessing the power of jupyter notebooks, the script in the cell below is a generalized way to create and populate a file named `progit.json`  using perceval.  \n",
    "\n",
    "The steps involved are simple: \n",
    "For each repository specified in the `repos_used` variable, fetch its git data, its pull_requests data and finally its issues data from the github api in that order and append them to `progit.json`. \n",
    "\n",
    "**Note**: it has been commented to prevent an accidental overwrite of the progit.json file, present in the parent directory of our present directory. To work on more recent data, or to perform an analysis on a completely different set of repositories, please uncomment the snippet below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo, repo_url in zip(repos_used, repo_urls):\n",
    "#     print(repo, repo_url)\n",
    "#     if repo == repos_used[0]:\n",
    "#         !perceval git --json-line $repo_url > ../progit.json\n",
    "\n",
    "#     else:\n",
    "#         !perceval git --json-line $repo_url >> ../progit.json\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category pull_request $owner $repo >> ../progit.json\n",
    "\n",
    "#     !perceval github -t $auth_token --json-line --sleep-for-rate --category issue $owner $repo >> ../progit.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the json file directly\n",
    "Even without the CleanJson class, perceval makes it very easy to analyze the data produced by it. A simple context manager to read the json file line-by-line will is all that's required.\n",
    "\n",
    "The contents of github_data will once populated will look something like:\n",
    "\n",
    "```python\n",
    "    {\n",
    "        'commit': [commit1_dict, commit2_dict, ....], \n",
    "        'issue': [issue1_dict, issue2_dict, ....], \n",
    "        'pull_request': [pr1_dict, pr2_dict, ....], \n",
    "    }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = 3 # ask asked in problem statement\n",
    "\n",
    "\n",
    "def get_date_range(months):\n",
    "    current_date = datetime.datetime.now()\n",
    "    timediff = datetime.timedelta(hours=24*30*months)\n",
    "    start_date = current_date - timediff    \n",
    "    return start_date\n",
    "\n",
    "start_date = get_date_range(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(date_string, start_date):\n",
    "    try:\n",
    "        datetimestr =  datetime.datetime.strptime(date_string, \"%a %b %d %H:%M:%S %Y %z\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "    except ValueError as ve:\n",
    "        datetimestr =  datetime.datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    finally:\n",
    "        datetimeobj = datetime.datetime.strptime(datetimestr, \"%Y-%m-%d\")\n",
    "        if datetimeobj >= start_date:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_data =  {\n",
    "                \"commit\": [], \n",
    "                \"issue\": [], \n",
    "                \"pull_request\": []\n",
    "                }\n",
    "\n",
    "\n",
    "with open('../progit.json', 'r') as github_data_file:\n",
    "    for line in github_data_file:\n",
    "        data_line = json.loads(line)\n",
    "        category = data_line['category']\n",
    "        if category == \"commit\":\n",
    "            if in_range(data_line[\"data\"][\"CommitDate\"], start_date):\n",
    "                github_data[category].append(data_line)\n",
    "        else:\n",
    "            if in_range(data_line[\"data\"][\"created_at\"], start_date):\n",
    "                github_data[category].append(data_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of pull requests and issues\n",
    "\n",
    "Lets create a dictionary `repo_wise_issues_prs`, whose structure is shown below: \n",
    "```python\n",
    "    {\n",
    "        repo_url_1: {\"issue\": .., \"pull_request\": ..}, \n",
    "        repo_url_2: {\"issue\": .., \"pull_request\": ..},\n",
    "        repo_url_3: {\"issue\": .., \"pull_request\": ..}, \n",
    "        ..\n",
    "        .\n",
    "    }\n",
    "```\n",
    "The generic keys used allow this part of the script to work no matter which repositories or projects are used for the analysis.\n",
    "\n",
    "Looping through each issue and pull request in `github_data`, simply populate `repo_wise_issues_prs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"https://github.com/progit/progit2-ru\": {\n",
      "        \"issue\": 18,\n",
      "        \"pull_request\": 18,\n",
      "        \"commit\": 30\n",
      "    },\n",
      "    \"https://github.com/progit/progit2-zh\": {\n",
      "        \"issue\": 4,\n",
      "        \"pull_request\": 3,\n",
      "        \"commit\": 6\n",
      "    }\n",
      "}\n",
      "Total number of issues:  22\n",
      "Total number of pull requests:  21\n"
     ]
    }
   ],
   "source": [
    "repo_wise_data = {repo_url: {\"issue\": 0, \"pull_request\": 0, \"commit\": 0} for repo_url in repo_urls}\n",
    "total_issues = 0\n",
    "total_prs = 0\n",
    "total_commits = 0\n",
    "\n",
    "for elem in github_data['issue']:\n",
    "    repo_wise_data[elem['origin']]['issue'] += 1\n",
    "    total_issues += 1\n",
    "    \n",
    "for elem in github_data['pull_request']:\n",
    "    repo_wise_data[elem['origin']]['pull_request'] += 1\n",
    "    total_prs += 1\n",
    "    \n",
    "for elem in github_data['commit']:\n",
    "    repo_wise_data[elem['origin']]['commit'] += 1\n",
    "    total_commits += 1\n",
    "\n",
    "print(json.dumps(repo_wise_data, indent=4))\n",
    "print(\"Total number of issues: \", total_issues)\n",
    "print(\"Total number of pull requests: \", total_prs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-71e2f76e385d>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-71e2f76e385d>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    with open(file_path, 'w') as csvfile:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def write_to_csv(file_path, repo_wise_data):\n",
    "    \n",
    "    repo_wise_data = dict(sorted(repo_data_wise.items(), key=lambda tup: (tup[1][\"issue\"]) + (tup[1][\"pull_request\"]) + (tup[1][\"commit\"])\n",
    "    \n",
    "    with open(file_path, 'w') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',')\n",
    "        \n",
    "        file_headers = [\"Repository\", \"Commits\", \"Num_Commits\", \"Num_Issues\", \"Num_PRs\", \"Total\"]\n",
    "        csv_writer.writerow(file_headers)\n",
    "        \n",
    "        for quar in quar_list:\n",
    "            row = [str(quar.number),         \\\n",
    "                 str(quar.year),             \\\n",
    "                 str(quar.num_commits) ,     \\\n",
    "                 str(quar.num_issues)  ,     \\\n",
    "                 str(quar.num_pullrequests), \\\n",
    "                 str(quar.new_committers),   \\\n",
    "                 str(quar.new_issue_subs),   \\\n",
    "                 str(quar.new_pr_subs)       \n",
    "                  ]\n",
    "            csv_writer.writerow(x for x in row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(file_path):\n",
    "    with open(file_path, 'r', ) as csvfile:\n",
    "        csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "        for row in csv_reader:\n",
    "            for field in row:\n",
    "                print(\"%-10s\" %field, end=\"\\t\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': [2, -10], 'x': [1, 2], 'z': [-1, 100]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"x\": [1, 2], \"y\": [2, -10], \"z\": [-1, 100]}\n",
    "dict(sorted(a.items(), key=lambda kv: sum(kv[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
